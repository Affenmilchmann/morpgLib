{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7a91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.morphLib import MorphAn\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "m_an = MorphAn('text')\n",
    "#m_an.load('results/prest_n_nakaz.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Tokenizing] [#########################] (1/1) 100% | Estimated time: 00h 00m 00s'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "folder_name = \"prest_n_nakaz\"\n",
    "mypath = f\"texts/{folder_name}/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and (f.endswith('.txt')))]\n",
    "str(len(onlyfiles)) + ' txt files'\n",
    "\n",
    "import re\n",
    "from src.TxtBar import TxtBar\n",
    "t_bar = TxtBar()\n",
    "\n",
    "t_bar.set_name('Tokenizing')\n",
    "\n",
    "for file_name in t_bar.seq(onlyfiles):\n",
    "    with open(mypath + file_name, 'r', encoding='utf8') as read_f:\n",
    "        file_data = read_f.read()\n",
    "        \n",
    "    clean_data = \"\"\n",
    "    for line in file_data.split('\\n'):\n",
    "        line_norm = line.strip().lower()\n",
    "        if line_norm.startswith('глава'):\n",
    "            continue\n",
    "        if not re.search('[a-zA-ZА-Яа-я]', line_norm):\n",
    "            continue\n",
    "        clean_data += line + '\\n'\n",
    "    m_an.sent_segmentation(clean_data, get_tokens=True, overwrite_tokens=False)\n",
    "\n",
    "#m_an.load_tokens('results/putin.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec38aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_an.sent_normalization(get_norm_forms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea48b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_an.save('results/prest_n_nakas.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb85bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(m_an.norm_forms), len(m_an.tokens), len(m_an.sentences), len(m_an.norm_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dd18eb9130b2bdf528b55e6b9d0229966df3b79bb22d703689a1f050e5ef0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
